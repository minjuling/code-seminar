{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "\n",
    "**정의된 dataset을 가지고 batch 단위로 학습하기 위해 data를 sampling 해주는 iterator**  \n",
    "mini batch를 만들어주는 역할\n",
    "\n",
    " dataset의 전체 데이터가 batch size로 slice된다. 앞서 만들었던 dataset을 input으로 넣어주면 여러 옵션(데이터 묶기, 섞기, 알아서 병렬처리)을 통해 batch를 만들어준다. 서버에서 돌릴 때는 num_worker를 조절해서 load속도를 올릴 수 있지만, PC에서는 default로 설정해야 오류가 안난다.\n",
    "\n",
    "dataloader에서 하는 일은 다음과 같다\n",
    "\n",
    "- 정의된 dataset에서 batch size 만큼 data `sampling`\n",
    "- sampling 된 data를 concat 해서 return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader overview\n",
    "\n",
    "**정의된 dataset을 가지고 batch 단위로 data를 만들어서 return 해줌**\n",
    "\n",
    "1. dataloader에 정의된 sampler에서 batch 개수 만큼 `data sampling`을 진행\n",
    "2. dataset에 정의된 getitem()을 사용해 `training data 읽어 들임`\n",
    "3. dataloader에 정의된 collate_fn 내부에서 batch 개수 만큼 뽑은 data를 `concat`\n",
    "    \n",
    "    → 만약, concat 과정에서 data shape이 다르면 concat operation error가 남\n",
    "    \n",
    "    → 이 경우에는 custom collate_fn()을 만들어서 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "tr_dataset = Dataset(train_x, train_y)\n",
    "train_loader = data.DataLoader(dataset=tr_dataset, batch_size=128, num_workers=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배치샘플러가 배치가 3이면 미니배치 사이즈 만큼의 데이터 개수 만큼 묶음. \n",
    "\n",
    "데이터 셋이 variable length이면 collate_fn을 이용해서\n",
    "배치로 묶어야할 미니배치의 데이터를 묶어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "class CustomDataLoader(data.DataLoader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomDataLoader, self).__init__(*args, **kwargs)\n",
    "        self.collate_fn = _collate_fn\n",
    "\n",
    "\n",
    "def _collate_fn(batch):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        batch: list, len(batch) = 1. See AudioDataset.__getitem__()\n",
    "        DataLoader 에 배치 크기(batch size)가 있는 배치(batch) 데이터\n",
    "    Returns:\n",
    "        mix_torch: B x ch x T, torch.Tensor\n",
    "        liens_torch : B, torch.Tentor\n",
    "        src_torch: B x C x T, torch.Tensor\n",
    "        \n",
    "    ex)\n",
    "    torch.Size([3, 6, 64000])\n",
    "    tensor([64000, 64000, 64000], dtype=torch.int32)\n",
    "    torch.Size([3, 2, 64000])\n",
    "    \"\"\"\n",
    "    x_tensor=[]\n",
    "    y_tensor=[]\n",
    "    for i in batch[0][0]:\n",
    "    \tx = lbrosa.load(\"~.wav\", sr)\n",
    "        x = torch.from_numpy(pad_sequence(x))\n",
    "        y = torch.from_numpy(np.load(\"~.npy\"))\n",
    "        x_tensor.append(x)\n",
    "        y_tensor.append(y)\n",
    "        \n",
    " \n",
    "    return x_tensor, y_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **학습 시 image data를 사용할 때 주의할 사항**\n",
    "\n",
    "- RGB image 값을 그대로 사용하지 않고 `normalize` 진행 후 사용\n",
    "- normalize를 하기 위한 mean, variance 값은 학습 하는 task에 따라 다르게 사용할 수 있다\n",
    "- ImageNet pretraining weight를 사용하는 경우, ImageNet에서 사용하는 mean, variance 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\t# * build DATALODER * #\n",
    "    # build_train_loader(), build_val_loader()에서 dataloader를 생성 후 return\n",
    "\ttrain_loader = build_train_loader(cfg)\n",
    "\tval_loader = build_val_loader(cfg)\n",
    "\n",
    "\tfor epoch in range(cfg.TRAIN.START_EPOCH, cfg.TRAIN.END_EPOCH+1):\n",
    "        train_loss, train_metrics  = train(model, train_loader, optimizer, epoch, cfg)\n",
    "        val_loss, val_metrics = validation(model, val_loader, epoch, cfg)\n",
    "\n",
    "def train():\n",
    "    # train()에서 iteration을 하며 batch 단위로 data를 받음\n",
    "    # enumerate: python 반복문 사용시 해당하는 data와 index 번호를 tuple 형태로 반환\n",
    "\n",
    "\tfor i_iter, inputs in enumerate(train_loader):\n",
    "\t\t# training code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader Parameters\n",
    "\n",
    "Params | type | Description\n",
    "---|---|---\n",
    "dataset | Dataset | training data를 Loading할 dataset class \n",
    "batch_size | int | 하나의 batch당 몇개의 sample load할건지 (default = 1) \n",
    "shuffle | bool | True로 설정 시, 매 epoch마다 전체 데이터셋을 shuffle (default = False) \n",
    "sampler | Sampler | dataset으로부터 샘플링하기 위한 방법. sampler가 정의 되면 shuffle은 False\n",
    "batch_sampler | Sampler | sampler와 비슷하지만, 한번에 하나의 배치에 해당하는 index sampling\n",
    "num_workers | int | Data loading을 위해 사용할 subprocess의 개수\n",
    "collate_fn | callable | sampling된 데이터 리스트를 하나의 mini-batch tensor로 만들어주는 함수\n",
    "pin_memory | bool | True인 경우 데이터 로더는 이 데이터를 return 하기 전에 CUDA pinned memory에 copy\n",
    "drop_last | bool | True로 설정 시, 전체 dataset 길이를 batch size로 나눴을 때 나눠 떨어지지 않는 데이터 셋들을 학습시킬때 제외 (default = False)\n",
    "timeout | numeric | positive인 경우, worker들로부터 하나의 batch를 모으는데 정해놓은 timeout 값(default = 0)\n",
    "worker_init_fn | callable | None이 아닌 경우 각 worker subprocess에서 worker id와 함께 호출 (default = None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader in Distributed Training\n",
    "\n",
    "Distributed training을 할 때, sampler를 `DistributedSampler`로 사용해줘야 한다.\n",
    "\n",
    "DistributedSampler는 전체 dataset을 gpu 개수로 나눠서 각각에 대한 sampler를 만들고 각 process에 할당한다. \n",
    "\n",
    "sampler는 iter method에서 dataset에 대한 index를 가지고 있는데, 하나의 sampler가 가지고 있는 index는 각 gpu에서 data가 exclusive 하게 설정된다."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "735ca55e8a53331c767e7660433af029be6a86c33db711221777f5c3fb9431ee"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('kaucar': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
